### Kafka的分区设计
1. 生产者并行写入受到分区数量的限制。
2. 消费者并行消费也受到消费分区数量限制。假设分区数量是20，则最大并发消费的消费者数量也是20.
3. 每个主题都包含固定数量的分区。分区数量决定单个中间件可能具有的不会显著影响性能的最大主题数量
### [如何选择kafka集群中的主题/分区数量](https://www.confluent.io/blog/how-choose-number-topics-partitions-kafka-cluster)
1. 更多的分区数量可以提高吞吐量
> 主题分区是Kafka中并行度的单位，在生产者和中间件端，对不同分区的写入可以完全并行完成。在消费者端，Kafka总是将
一个分区的数据提供给一个消费者线程。因此，消费者(在消费者组内)的并行度受到消费分区的数量限制。所以，在Kafka集群
中的分区越多，实现的吞吐量就越高。

> 选择分区数量的粗略公式基于吞吐量。可以在单个分区中对实现的生产者P和消费者C进行测量吞吐量T。然后你至少需要
max(T/P,T/C)的分区数量，在生产者上实现的单个分区的吞吐量取决于一些配置，如：批处理大小，压缩编解码器，ack类型，
复制因子等。但是一般情况下，如本基准测试所示，只能在一个分区上以10 MB/S 的速度生成。      
消费者的吞吐量通常取决于应用程序，因为它对应于消费者逻辑处理每条消息的速度。需要实际测量。

> 尽管随着时间的推移可以增加分区数量，但如果是使用Key生产消息，必须要小心。在发布消息时，Kafka根据Key的
哈希值明确地将消息映射到对应分区。这样可以保证具有相同Key的消息始终路由到同一分区。这种保证对于某些应用程序很重要
，因为分区内的消息总是按照消费者的要求传递。如果分区数量改变，这种保证可能不再使用。为了避免这种情况，一种常见的
做法是过度分区。基本上，你需要根据后续一两年的吞吐量来确定分区数量，最初，你可以根据当前吞吐量设置一个小型的Kafka
集群，一段时间后，你可以向集群中添加更多的中间件，并按照比例将现有分区的子集移动到新的中间件中。（可以在线完成）。
这样，你就可以在使用Key不破坏应用程序语义的情况下，继续保持吞吐量的增长。

### 更多分区需要打开更多文件句柄
> 每一个分区都对应中间件文件系统中的目录。在一个日志目录中,每个日志段将有两个文件(一个用于索引，一个用于实际数据)。    
目前，在Kafka中，每个中间件要打开每个日志段的索引和数据文件的文件句柄。所以，分区越多，需要在底层操作系统中配置
最多打开文件句柄的值就越高。这主要是配置问题，我们已经看到生产的Kafka集群运行着的每个中间件可以打开超过3万个文件句柄。

### 更多的分区会降低可用性
> Kafka支持集群内复制，这样可以提供更高的可用性和耐用性。一个分区可以有多个副本，每个副本存储在不同的中间件上。
其中一个副本被指定为领袖，其余的被指定为候选者。在内部，Kafka自动管理这些副本，并确保它们保持同步。生产者和消费者
都去请求作为领袖的副本，当中间件处理失败，在中间件上具有领袖的分区暂时不可用。Kafka会自动将这些不可用分区中的领袖副本
移动到其他副本，以便继续处理客户端请求。这个过程是由指定为控制器的一个Kafka中间件来完成。它涉及到在Zookeeper中为
每个受影响的分区读取和写入一些元数据。目前，对Zookeeper的操作是在控制器中连续完成的。

> 在中间件被彻底关闭的情况下，控制器会主动从已经关闭的中间件中将领袖副本逐一移出，单个领袖副本的移动只需要几毫秒。
所以，从客户端的角度来看，在一个中间件彻底关闭后只有一个小窗口不可用。

> 然而，如果中间件没有彻底关闭，观察到的不可用的可能性将会与分区数量成正比，假设一个中间件总共有2000个分区，每个
分区都有2个复制品，粗略地说，这个中间件上将有1000个分区的领导副本，当中间件失败时，所有这1000个分区在同一时间会
变得不可用。假设为单个分区选择新的领袖副本需要5ms,为所有1000个分区选择新的领袖副本最多需要5s,因此，对于某些分区，
它们观察到的不可用时间可能是5s的时间加上检测故障需要的时间。

> 更不幸的是，失败的中间件有可能是控制器，在这种情况下，在控制器故障转移到新的中间件之前，不会执行选取新的领袖副本
动作。控制器故障转移是自动发生，但要求新的控制器在初始化时从Zookeeper读取每个分区的一些元数据。例如，如果Kafka集群
中有10000个分区，并且从Zookeeper初始化时读取每个分区元数据需要2ms,总共就耗时20s,不可用窗口就会持续20s。

> 一般来说，没有彻底关闭的情况是罕见的。但是，如果要关系极少数情况的可用性，最好将每个中间件的分区数量限制为2-4千，
并将集群中的分区总数限制为数万个。

### 更多的分区可能会增加端到端延迟
> Kafka中的端到端延迟由生产者发布消息到消费者读取消息的时间来决定，Kafka只有在消费者提交后才向消费者公开消息，
比如，消息复制到所有同步副本时，因此，提交消息的时间可能是端到端延迟重要的部分。默认情况下，对于在两个中间件之间
共享副本的所有分区，Kafka中间件仅仅使用单个线程从另一个中间件复制数据。实验表明，将1000个分区从一个中间件复制到
另一个中间件可以增加大于20ms的延迟，这意味着端到端延迟至少为20ms。对于某些实时应用程序来说，这可能太高了。

> 请注意，这种问题可以在较大的集群上得到缓解。例如，假设中间件上有1000个分区的领袖副本，同一个Kafka集群中有10个
其他的中间件。其余10个中间件中的每个只需要平均从第一个中间件中获取100个分区，这样分担下来，由于提交消息而增加的
延迟将仅为几毫秒，而不是几十毫秒。

> 根据经验，如果你关心延迟，将每个中间件的分区数限制为100 * b * r 可能是个好主意，其中b是Kafka集群中的中间件个数，
r是复制因子。

### 更多的分区意味着客户端需要更多的内存
> 在我们随Confluent Platform 1.0发布的最新0.8.2版本中，我们开发了一个更高效的Java生产者。它的一个不错的功能是
它允许用户设置用于缓冲传入消息的内存量的上限。生产者在内部缓冲每个分区的消息。在累积了足够的数据或经过足够的时间
后，这些累积的消息将从缓冲区中移除，并发送给中间件。

> 如果增加分区数量，更多的消息将在生产者的更多分区中累积，使用的内存总量可能超过配置的内存限制。当这种情况发生时，
生产者必须阻止或删除任何新消息，但是这两种方式都不太理想。为了防止这种情况发生，需要重新配置更大内存的生产者。

> 根据经验，要实现良好的吞吐量，应该在生产者中为每个分区分配至少几十KB的内存，并在分区数量显著增加时，调整内存总量。

> 消费者也存在类似的问题。消费者从每个分区获取一批消息，消费者消费的分区越多，它需要的内存就越多，然而对于非实时
的消费者而言，这通常只是一个问题。

### 结语
> 通常，Kafka集群中的更多分区会带来更多的吞吐量，但是，必须意识到的是，一个中间件拥有太多的分区会给可用性和端到端
延迟等带来影响。在未来，我们计划改进其中的一些限制，以便使Kafka在分区数量方面更具有可扩展性。

#### RocketMQ 不能实现主从切换！！！


